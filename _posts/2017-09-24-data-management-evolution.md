---
layout: post
title: 数据访问与管理技术的演进
comments: true
categories: [design]
tags: [design, architecture, database, microservice]
---

数据访问和管理是软件设计需要解决的一项非常关键而又基础的问题;从早期的大型Unix应用开始，到基于C/S架构的商业应用，
乃至在互联网大潮中取得压倒性优势的基于B/S架构的企业应用，对于如何管理、访问、保存、检索、备份、维护数据这一基本问题，
无数先辈们创造了丰富多样的技术选项，然而随着行业潮流的变换，不同的技术依然在它各自适应的领域闪耀这光芒。

<!--more-->
## 数据访问、管理技术的关键要素
到目前为止，几乎所有的软件依然是工作在冯诺依曼设定的计算机架构之上,因而从**最微观的粒度看,运算器、控制器、存储设备互相配合**完成形形色色的任务。
各色复杂的软件都要在此基础上做更高层次的抽象和封装，才能完成复杂度更高的任务。程序语言、编译器和各种各样的库函数、中间件等则都围绕着该基本模型来处理高层次的领域相关问题。

由于最底层的硬件要么具有访问速度快但易失性的特点，要么是访问速度慢但可以持续保存很长时间；同时硬件在长时间工作的情况下总会面临各种各样的失败。
面向业务问题的计算机**软件必须要被仔细设计以隔离上述问题，使得用户觉得失败永远不可能发生**（或者至少是现实意义上的不会失败）。
这对数据的访问和管理技术提出了很高的挑战
- 数据容量在需要的情况下能尽可能地大，甚至是可以**按需动态扩展**；传统上基于单机的数据存储模型被扩展到可以被存储在地理上分散的网络节点
- 数据访问的延时需要满足特定的场景需求；由于数据可能被存放在不同的设备上，不同的存储设备有不同的访问性能和时延特性
- 多用户同时访问的一致性：复杂的应用总会允许有逻辑上同时访问数据的需求，如果是访问同样的数据或者相互有逻辑关联的数据，用户不应该得到不一致的数据状态
- 数据的可靠性：在任何硬件失效的情况下，数据的丢失总是应该被尽量杜绝的

这些目标、挑战有些是互相矛盾的，因此在现有的技术条件下并没有出现过一种一招通吃的方案，各色各样的技术方案都会在某些方面有所取舍。
只是在同样的取舍考虑下，优秀的技术能比它的竞争对手们做的更为出色。

## 前“关系数据库”时期的数据结构和文件方案
在20世纪70年代关系数据库理论出现之前，软件已经被用于解决很多形形色色的问题了， 这个时期其实并没有专门针对数据管理的特定技术。

### 基于操作系统和基本库的思路
需要管理和访问数据的时候，最基本的方案就是依赖操作系统和编程语言提供的基础设施了。
这种场景下数据的访问**基本是没有很强的结构化特性**的，软件的规模也不是太大，因而直接依赖于底层的机制也算够用了。

数据组织上基本以常用的数据结构为主，从最简单的顺序数组，到稍微复杂一点的链表结构，乃至树形结构、跳表、哈希表等依赖于计算机内部存储（处理器寄存器乃至内存）的高效数据机构。这些数据组织方式特别适合于规模不大的数据管理；
其优点是数据的访问和存取都比较高效，然而其限制也比较明显，数据量比较大的时候，就必须找数据持久化存储的方法。

一种最简单的方式是将数据用文件的方式写入到外部存储设备中；然后在需要的时候在从外部设备加载回来。
数据量超过内部存储容量（或者超出预先分配的空间）的时候，可以用选择性的方式将某些数据换回到外部设备中。

### 问题和挑战
带来的挑战是如何选择合适的算法来确定什么时候需要将数据保存到外部存储设备，或者何时需要将数据加载到内存中；另外一个难题是如果存储设备出错了，应该怎样应对这些错误。
应为应用程序的处理逻辑和数据管理、控制逻辑是放在一起的，这些异常处理和策略选择会使软件的逻辑复杂度大大提高。

另外一个挑战是当数据容量变得特别巨大的时候，不可避免的需要将存储设备放在不同的物理机器上，
然后通过网络通信协议的方式（比如NFS）将远端机器上的文件系统挂载在本地机器上；使本地机器以为它是在控制“本地”的文件;
而微观上所有的操作都是通过一个网络通信通道（socket）加上对应的控制协议和数据搬运协议来完成。

从寄存器到内存到磁盘再到网络磁盘，数据的容量是越来越大，然而其性能和延迟也急速下降；对CPU寄存器的访问可能几个时钟周期就可以完成（虽然其容量很小），
对内存的一次读写需要的时间就会达到几十乃至数百倍，访问本地磁盘的延时往往是毫秒级甚至几十毫秒；当文件被用NFS的方式映射到本地的时候，
一次访问的时间可能在数十毫秒乃至数秒。

这些时间上的开销给软件开发带来了诸多挑战 - 长时间的延时（要么是库函数调用要么是系统调用）导致同步调用变得效率底下，甚至抵消了多线程编程带来的便利。
因为太多阻塞的操作导致处理器使用率底下，更高的吞吐率难以达到，我们不得不借助于异步变成技术来分割应用程序的逻辑。

可惜的是，因为IO行为的差异引发的编程模型的转化是的软件的可维护行大大降低。
试想一个简单的业务逻辑因为需要访问外部存储设备而被分割成２个任务，丢在２个不同的线程调度器里，通过IO完成的callback事件关联在一起；
这比基于内存数据的顺序处理逻辑复杂多了。
虽然函数式变成模型或者Reactor模型可以应对这一设计挑战，但是仅仅因为数据访问的原因而变更熟悉的编程模型并不是在很多场景下都可以被轻易接受；
毕竟软件开发是依赖于人的集体智力活动。

### 对软件设计和架构的影响
这些**非功能的属性会极大影响到应用程序的逻辑设计**；软件设计人员不得不在开发的早期阶段谨慎选择，以免掉入性能不足的漩涡最后不得不重写代码。
本来软件的抽象是为了解决应用领域的复杂问题，隔离底层的细节，不幸的是**当底层细节的不同影响到了程序整体的行为的时候，这种关注点分离的方式就很难凑效**。
尽管有各种各样的限制，在很多复杂度不是很高的场景下，基于操作系统和基础设施的数据管理方案仍然是最直观且最优的选择。
只要切记在合适的时机依据需求的变化切换到更合适的方案上来即可；要么是变更的成本不大可以直接修改代码完成之，要么是一开始的时候设计好数据访问的隔离，
才与适配器的模式隔离数据访问部分。

## 基于严格结构化的关系数据库技术(SQL)

关系数据库技术自从上个世纪７０～８０年代诞生以来便得到了业界的青睐；其清晰的模型和严格的数学理论论证深刻地征服了各个主要的IT厂商，
其采用专门的属于来规范数据的定义和各种功能、非功能属性，学院式的精心设计预先考虑到了各种各样的问题。

### 基本机制和思路
关系数据库理论采用结构化的方式定义数据，严格的区分数据定义、处理的范围和边界。
数据库管理系统作为专门的软件系统隔离了数据的定义、操作；应用程序通过预先定义的接口JDBC/ODBC等接口访问数据库系统。

#### 数据定义
数据的**结构抽象用schema来表述，逻辑上所有的数据都是满足给定schema的二维表**，每一行是一条记录；所有的记录都具有相同的列。
每一行数据的相同列具有相同的定义和约束；每一行数据中的某些列作为访问的关键列（称为键）。这些列有些可以为空有些则必须不能为空。
对数据的访问则以行为单位，可以进行增加、删除、修改等变更性操作和根据某些条件进行查询。
数据的完整性校验可以通过在数据发生变更的时候自动检查来完成。

数据表之间可以有丰富多样的相互关联(通过主键、外键设置)，从而支持在查询的时候跨越多个表进行复杂的检索。
为了便于应用逻辑处理，关系数据库系统还提供了虚拟的表（称之为视图），这些虚拟的表结构可以基于底层实际的"物理记录表"信息的变化而自动更新；
触发器则支持设置类似于应用程序指定的“自动操作”，当对应的数据被更新的时候，触发器会被自动运行。

#### 数据查询和SQL语言

#### ACID属性

### 问题和挑战 

## 互联网技术深入发展下的非结构化数据和NoSQL技术

## 微服务架构下的数据演进和NewSQL